{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Friday's blog For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"\u4e3b\u9875"},{"location":"#welcome-to-fridays-blog","text":"For full documentation visit mkdocs.org .","title":"Welcome to Friday's blog"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"ML/","text":"","title":"Machine learning\u5bfc\u8bfb"},{"location":"ML/Neural network-Multiple categories/","text":"\u5229\u7528\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u89e3\u51b3\u624b\u5199\u6570\u5b57\u56fe\u50cf\u8bc6\u522b\u7684\u591a\u5206\u7c7b\u95ee\u9898 \u591a\u5206\u7c7b\u795e\u7ecf\u7f51\u7edc\u7b97\u6cd5\u6d41\u7a0b\uff08BP\u7b97\u6cd5\u6d41\u7a0b\uff09\uff1a \u5728\u624b\u5de5\u8bbe\u5b9a\u4e86\u795e\u7ecf\u7f51\u7edc\u7684\u5c42\u6570\uff0c\u6bcf\u5c42\u795e\u7ecf\u5143\u7684\u4e2a\u6570\uff0c\u5b66\u4e60\u7387 \u03b7 \u540e\uff0cBP \u7b97\u6cd5\u4f1a\u5148\u968f\u673a\u521d\u59cb\u5316\u6bcf\u6761\u8fde\u63a5\u7ebf\u6743\u91cd\u548c\u504f\u7f6e\uff0c\u7136\u540e\u5bf9\u4e8e\u8bad\u7ec3\u96c6\u4e2d\u7684\u6bcf\u4e2a\u8f93\u5165 X \u548c\u8f93\u51fa y\uff0cBP \u7b97\u6cd5\u90fd\u4f1a\u5148\u6267\u884c\u524d\u5411\u4f20\u8f93\u5f97\u5230\u9884\u6d4b\u503c\uff0c\u7136\u540e\u6839\u636e\u771f\u5b9e\u503c\u4e0e\u9884\u6d4b\u503c\u4e4b\u95f4\u7684\u8bef\u5dee\u6267\u884c\u9006\u5411\u53cd\u9988\u66f4\u65b0\u795e\u7ecf\u7f51\u7edc\u4e2d\u6bcf\u6761\u8fde\u63a5\u7ebf\u7684\u6743\u91cd\u548c\u6bcf\u5c42\u7684\u504f\u597d\u3002\u5728\u6ca1\u6709\u5230\u8fbe\u505c\u6b62\u6761\u4ef6\u7684\u60c5\u51b5\u4e0b\u91cd\u590d\u4e0a\u8ff0\u8fc7\u7a0b\u3002 \u505c\u6b62\u7684\u6761\u4ef6\u6709\u4e0b\u9762\u4e09\u79cd\uff1a \u6743\u91cd\u7684\u66f4\u65b0\u4f4e\u4e8e\u67d0\u4e2a\u9600\u503c\u65f6 \u8fbe\u5230\u9884\u8bbe\u7684\u8fed\u4ee3\u6b21\u6570\uff08\u6211\u4eec\u8fd9\u6b21\u8bd5\u9a8c\u9009\u62e9\u4e86\u8fd9\u79cd\u505c\u6b62\u6761\u4ef6\uff09 \u9884\u6d4b\u7684\u9519\u8bef\u7387\u4f4e\u4e8e\u67d0\u4e2a\u9600\u503c \u6bcf\u8f93\u5165\u4e00\u4e2a\u5b9e\u4f8b\uff0c\u795e\u7ecf\u7f51\u7edc\u4f1a\u6267\u884c\u524d\u5411\u8f93\u51fa\u4e00\u5c42\u5c42\u8ba1\u7b97\u5230\u8f93\u51fa\u795e\u7ecf\u5143\u7684\u503c\uff0c\u901a\u8fc7\u8fc7\u54ea\u4e00\u4e2a\u8f93\u51fa\u795e\u7ecf\u5143\u7684\u503c\u6700\u5927\u6765\u9884\u6d4b\u8f93\u5165\u7684\u5b9e\u4f8b\u6240\u4ee3\u8868\u7684\u6570\u5b57\u3002\u7136\u540e\u6839\u636e\u8f93\u51fa\u795e\u7ecf\u5143\u7684\u503c\uff0c\u8ba1\u7b97\u51fa\u9884\u6d4b\u503c\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u7684\u8bef\u5dee\uff0c\u518d\u9006\u5411\u53cd\u9988\u66f4\u65b0\u795e\u7ecf\u7f51\u7edc\u4e2d\u6bcf\u6761\u8fde\u63a5\u7ebf\u7684\u6743\u503c\u548c\u6bcf\u4e2a\u795e\u7ecf\u5143\u7684\u504f\u597d\u3002 \u524d\u5411\u4f20\u8f93\uff08Feed-Forward\uff09 \u8f93\u5165\u5c42-->\u9690\u85cf\u5c42-->\u8f93\u51fa\u5c42\u9010\u5c42\u7684\u8ba1\u7b97\u6240\u6709\u795e\u7ecf\u5143\u8f93\u51fa\u503c\u7684\u8fc7\u7a0b\u3002 \u8bef\u5dee\u9006\u4f20\u8f93\uff08error BackPropagation\uff09 \u7531\u4e8e\u8f93\u51fa\u5c42\u7684\u503c\u4e0e\u771f\u5b9e\u503c\u4f1a\u5b58\u5728\u8bef\u5dee\uff0c\u7528\u5747\u65b9\u8bef\u5dee\u6765\u8861\u91cf\u9884\u6d4b\u503c\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u7684\u8bef\u5dee \u9006\u5411\u53cd\u9988\u7684\u76ee\u6807\u5c31\u662f\u8ba9E\u51fd\u6570\u7684\u503c\u5c3d\u53ef\u80fd\u7684\u5c0f\uff0c\u800c\u6bcf\u4e2a\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u503c\u662f\u7531\u8be5\u70b9\u7684\u8fde\u63a5\u7ebf\u5bf9\u5e94\u7684\u6743\u91cd\u503c\u548c\u8be5\u5c42\u5bf9\u5e94\u7684\u504f\u597d\u6240\u51b3\u5b9a\u7684\uff0c\u56e0\u6b64\uff0c\u8981\u8ba9\u8bef\u5dee\u51fd\u6570\u8fbe\u5230\u6700\u5c0f\uff0c\u6211\u4eec\u5c31\u8981\u8c03\u6574w\u548cb\u503c\uff0c \u4f7f\u5f97\u8bef\u5dee\u51fd\u6570\u7684\u503c\u6700\u5c0f\u3002 \u5bf9\u76ee\u6807\u51fd\u6570 E \u6c42 w \u548c b \u7684\u504f\u5bfc\u53ef\u4ee5\u5f97\u5230 w \u548c b \u7684\u66f4\u65b0\u91cf\uff0c\u4e0b\u9762\u62ff\u6c42 w \u504f\u5bfc\u6765\u505a\u63a8\u5bfc \u5176\u4e2d \u03b7 \u4e3a\u5b66\u4e60\u7387\uff0c\u53d6\u503c\u901a\u5e38\u4e3a 0.1 ~ 0.3,\u53ef\u4ee5\u7406\u89e3\u4e3a\u6bcf\u6b21\u68af\u5ea6\u6240\u8fc8\u7684\u6b65\u4f10\u3002\u6ce8\u610f\u5230 w_hj \u7684\u503c\u5148\u5f71\u54cd\u5230\u7b2c j \u4e2a\u8f93\u51fa\u5c42\u795e\u7ecf\u5143\u7684\u8f93\u5165\u503ca\uff0c\u518d\u5f71\u54cd\u5230\u8f93\u51fa\u503cy\uff0c\u6839\u636e\u94fe\u5f0f\u6c42\u5bfc\u6cd5\u5219\u6709 \u6839\u636e\u795e\u7ecf\u5143\u8f93\u51fa\u503c a \u7684\u5b9a\u4e49\u6709 Sigmoid \u6c42\u5bfc\u6570\u7684\u5f0f\u5b50\u5982\u4e0b \uff1a \u56e0\u800c\uff1a \u5219\u6743\u91cd w \u7684\u66f4\u65b0\u91cf\u4e3a \uff1a \u540c\u7406\u53ef\u5f97b\u7684\u66f4\u65b0\u91cf\u4e3a\uff1a \u4f46\u8fd9\u4e24\u4e2a\u516c\u5f0f\u53ea\u80fd\u591f\u66f4\u65b0\u8f93\u51fa\u5c42\u4e0e\u524d\u4e00\u5c42\u8fde\u63a5\u7ebf\u7684\u6743\u91cd\u548c\u8f93\u51fa\u5c42\u7684\u504f\u7f6e\uff0c\u539f\u56e0\u662f\u56e0\u4e3a \u03b4 \u503c\u4f9d\u8d56\u4e86\u771f\u5b9e\u503cy\u8fd9\u4e2a\u53d8\u91cf\uff0c\u4f46\u662f\u6211\u4eec\u53ea\u77e5\u9053\u8f93\u51fa\u5c42\u7684\u771f\u5b9e\u503c\u800c\u4e0d\u77e5\u9053\u6bcf\u5c42\u9690\u85cf\u5c42\u7684\u771f\u5b9e\u503c\uff0c\u5bfc\u81f4\u65e0\u6cd5\u8ba1\u7b97\u6bcf\u5c42\u9690\u85cf\u5c42\u7684 \u03b4 \u503c\uff0c\u6240\u4ee5\u6211\u4eec\u5e0c\u671b\u80fd\u591f\u5229\u7528 i+1 \u5c42\u7684 \u03b4 \u503c\u6765\u8ba1\u7b97 i \u5c42\u7684 \u03b4 \u503c\uff0c\u800c\u6070\u6070\u901a\u8fc7\u4e00\u4e9b\u5217\u6570\u5b66\u8f6c\u6362\u540e\u53ef\u4ee5\u505a\u5230\uff0c\u8fd9\u4e5f\u5c31\u662f\u9006\u5411\u53cd\u9988\u540d\u5b57\u7684\u7531\u6765\uff0c\u516c\u5f0f\u5982\u4e0b: \u4ece\u4e0a\u9762\u7684\u5f0f\u5b50\uff0c\u53ea\u9700\u8981\u77e5\u9053\u4e0b\u4e00\u5c42\u7684\u6743\u91cd\u7684\u795e\u7ecf\u5143\u8f93\u51fa\u5c42\u7684\u503c\u5c31\u53ef\u4ee5\u8ba1\u7b97\u51fa\u4e0a\u4e00\u5c42\u7684 \u03b4 \u503c \uff0c\u53ea\u8981\u901a\u8fc7\u4e0d\u65ad\u5730\u5229\u7528\u4e0a\u9762\u7684\u5f0f\u5b50\u5c31\u53ef\u4ee5\u5c31\u53ef\u4ee5\u66f4\u65b0\u9690\u85cf\u5c42\u7684\u5168\u90e8\u6743\u91cd\u548c\u504f\u7f6e\u3002 \u4e0b\u9762\u7ed9\u51fa\u6b64\u6b21\u5b9e\u9a8c\u7684\u6e90\u7801\uff1a BPNetwork.py import numpy as np def tanh ( x ): return np . tanh ( x ) def tan_deriv ( x ): return 1.0 - np . tanh ( x ) * np . tan ( x ) # sigmoid def logistic ( x ): return 1 / ( 1 + np . exp ( - x )) def logistic_deriv ( x ): return logistic ( x ) * ( 1 - logistic ( x )) class NeuralNetwork : def __init__ ( self , layers , activation = 'tanh' ): if activation == 'logistic' : self . activation = logistic self . activation_deriv == logistic_deriv elif activation == 'tanh' : self . activation = tanh self . activation_deriv = tan_deriv self . weights = [] for i in range ( 1 , len ( layers ) - 1 ): self . weights . append (( 2 * np . random . random (( layers [ i - 1 ] + 1 , layers [ i ] + 1 )) - 1 ) * 0.25 ) self . weights . append (( 2 * np . random . random (( layers [ i ] + 1 , layers [ i + 1 ])) - 1 ) * 0.25 ) def fit ( self , X , y , learning_rate = 0.2 , epochs = 10000 ): X = np . atleast_2d ( X ) temp = np . ones ([ X . shape [ 0 ], X . shape [ 1 ] + 1 ]) temp [:, 0 : - 1 ] = X X = temp y = np . array ( y ) for k in range ( epochs ): i = np . random . randint ( X . shape [ 0 ]) a = [ X [ i ]] for l in range ( len ( self . weights )): a . append ( self . activation ( np . dot ( a [ l ], self . weights [ l ]))) error = y [ i ] - a [ - 1 ] deltas = [ error * self . activation_deriv ( a [ - 1 ])] for l in range ( len ( a ) - 2 , 0 , - 1 ): deltas . append ( deltas [ - 1 ] . dot ( self . weights [ l ] . T ) * self . activation_deriv ( a [ l ])) deltas . reverse () for i in range ( len ( self . weights )): layer = np . atleast_2d ( a [ i ]) delta = np . atleast_2d ( deltas [ i ]) self . weights [ i ] += learning_rate * layer . T . dot ( delta ) def predict ( self , x ): x = np . array ( x ) temp = np . ones ( x . shape [ 0 ] + 1 ) temp [ 0 : - 1 ] = x a = temp for l in range ( 0 , len ( self . weights )): a = self . activation ( np . dot ( a , self . weights [ l ])) return a Run.py from BPNetwork import NeuralNetwork import numpy as np train = [ 0 , 0 , 0 , 0 , 0 ] test = [ 0 , 0 , 0 , 0 , 0 ] train [ 0 ] = [[ 0 , 1 , 1 , 0 , 0 ], [ 0 , 0 , 1 , 0 , 0 ], [ 0 , 0 , 1 , 0 , 0 ], [ 0 , 0 , 1 , 0 , 0 ], [ 0 , 1 , 1 , 1 , 0 ]] train [ 1 ] = [[ 1 , 1 , 1 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 1 ], [ 0 , 1 , 1 , 1 , 0 ], [ 1 , 0 , 0 , 0 , 0 ], [ 1 , 1 , 1 , 1 , 1 ]] train [ 2 ] = [[ 1 , 1 , 1 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 1 ], [ 0 , 1 , 1 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 1 ], [ 1 , 1 , 1 , 1 , 0 ]] train [ 3 ] = [[ 0 , 0 , 0 , 1 , 0 ], [ 0 , 0 , 1 , 1 , 0 ], [ 0 , 1 , 0 , 1 , 0 ], [ 1 , 1 , 1 , 1 , 1 ], [ 0 , 0 , 0 , 1 , 0 ]] train [ 4 ] = [[ 1 , 1 , 1 , 1 , 1 ], [ 1 , 0 , 0 , 0 , 0 ], [ 1 , 1 , 1 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 1 ], [ 1 , 1 , 1 , 1 , 0 ]] test [ 0 ] = [[ 0 , 0 , 1 , 1 , 0 ], [ 0 , 0 , 1 , 1 , 0 ], [ 0 , 1 , 0 , 1 , 0 ], [ 0 , 0 , 0 , 1 , 0 ], [ 0 , 1 , 1 , 1 , 0 ]] test [ 1 ] = [[ 1 , 1 , 1 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 1 ], [ 0 , 1 , 1 , 1 , 0 ], [ 1 , 0 , 0 , 0 , 1 ], [ 1 , 1 , 1 , 1 , 1 ]] test [ 2 ] = [[ 1 , 1 , 1 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 1 ], [ 0 , 1 , 1 , 1 , 0 ], [ 1 , 0 , 0 , 0 , 1 ], [ 1 , 1 , 1 , 1 , 0 ]] test [ 3 ] = [[ 0 , 1 , 1 , 1 , 0 ], [ 0 , 1 , 0 , 0 , 0 ], [ 0 , 1 , 1 , 1 , 0 ], [ 0 , 0 , 0 , 1 , 0 ], [ 0 , 1 , 1 , 1 , 0 ]] test [ 4 ] = [[ 0 , 1 , 1 , 1 , 1 ], [ 0 , 1 , 0 , 0 , 0 ], [ 0 , 1 , 1 , 1 , 0 ], [ 0 , 0 , 0 , 1 , 0 ], [ 1 , 1 , 1 , 1 , 0 ]] nn = NeuralNetwork ([ 25 , 50 , 5 ], 'tanh' ) # temp = init[0] for i in range ( 5 ): X = np . array ( train [ i ]) y = np . array ( test [ i ]) nn . fit ( X , y ) for j in train [ i ]: print ( nn . predict ( j )) \u5b9e\u9a8c\u9884\u6d4b\u6d4b\u8bd5\u96c6\u7ed3\u679c\uff1a","title":"\u795e\u7ecf\u7f51\u7edc\u57fa\u7840\u5b9e\u6218 - \u591a\u5206\u7c7b\u95ee\u9898"},{"location":"ML/Neural network-Multiple categories/#_1","text":"","title":"\u5229\u7528\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u89e3\u51b3\u624b\u5199\u6570\u5b57\u56fe\u50cf\u8bc6\u522b\u7684\u591a\u5206\u7c7b\u95ee\u9898"},{"location":"ML/Neural network-Multiple categories/#bp","text":"\u5728\u624b\u5de5\u8bbe\u5b9a\u4e86\u795e\u7ecf\u7f51\u7edc\u7684\u5c42\u6570\uff0c\u6bcf\u5c42\u795e\u7ecf\u5143\u7684\u4e2a\u6570\uff0c\u5b66\u4e60\u7387 \u03b7 \u540e\uff0cBP \u7b97\u6cd5\u4f1a\u5148\u968f\u673a\u521d\u59cb\u5316\u6bcf\u6761\u8fde\u63a5\u7ebf\u6743\u91cd\u548c\u504f\u7f6e\uff0c\u7136\u540e\u5bf9\u4e8e\u8bad\u7ec3\u96c6\u4e2d\u7684\u6bcf\u4e2a\u8f93\u5165 X \u548c\u8f93\u51fa y\uff0cBP \u7b97\u6cd5\u90fd\u4f1a\u5148\u6267\u884c\u524d\u5411\u4f20\u8f93\u5f97\u5230\u9884\u6d4b\u503c\uff0c\u7136\u540e\u6839\u636e\u771f\u5b9e\u503c\u4e0e\u9884\u6d4b\u503c\u4e4b\u95f4\u7684\u8bef\u5dee\u6267\u884c\u9006\u5411\u53cd\u9988\u66f4\u65b0\u795e\u7ecf\u7f51\u7edc\u4e2d\u6bcf\u6761\u8fde\u63a5\u7ebf\u7684\u6743\u91cd\u548c\u6bcf\u5c42\u7684\u504f\u597d\u3002\u5728\u6ca1\u6709\u5230\u8fbe\u505c\u6b62\u6761\u4ef6\u7684\u60c5\u51b5\u4e0b\u91cd\u590d\u4e0a\u8ff0\u8fc7\u7a0b\u3002","title":"\u591a\u5206\u7c7b\u795e\u7ecf\u7f51\u7edc\u7b97\u6cd5\u6d41\u7a0b\uff08BP\u7b97\u6cd5\u6d41\u7a0b\uff09\uff1a"},{"location":"ML/Neural network-Multiple categories/#_2","text":"\u6743\u91cd\u7684\u66f4\u65b0\u4f4e\u4e8e\u67d0\u4e2a\u9600\u503c\u65f6 \u8fbe\u5230\u9884\u8bbe\u7684\u8fed\u4ee3\u6b21\u6570\uff08\u6211\u4eec\u8fd9\u6b21\u8bd5\u9a8c\u9009\u62e9\u4e86\u8fd9\u79cd\u505c\u6b62\u6761\u4ef6\uff09 \u9884\u6d4b\u7684\u9519\u8bef\u7387\u4f4e\u4e8e\u67d0\u4e2a\u9600\u503c \u6bcf\u8f93\u5165\u4e00\u4e2a\u5b9e\u4f8b\uff0c\u795e\u7ecf\u7f51\u7edc\u4f1a\u6267\u884c\u524d\u5411\u8f93\u51fa\u4e00\u5c42\u5c42\u8ba1\u7b97\u5230\u8f93\u51fa\u795e\u7ecf\u5143\u7684\u503c\uff0c\u901a\u8fc7\u8fc7\u54ea\u4e00\u4e2a\u8f93\u51fa\u795e\u7ecf\u5143\u7684\u503c\u6700\u5927\u6765\u9884\u6d4b\u8f93\u5165\u7684\u5b9e\u4f8b\u6240\u4ee3\u8868\u7684\u6570\u5b57\u3002\u7136\u540e\u6839\u636e\u8f93\u51fa\u795e\u7ecf\u5143\u7684\u503c\uff0c\u8ba1\u7b97\u51fa\u9884\u6d4b\u503c\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u7684\u8bef\u5dee\uff0c\u518d\u9006\u5411\u53cd\u9988\u66f4\u65b0\u795e\u7ecf\u7f51\u7edc\u4e2d\u6bcf\u6761\u8fde\u63a5\u7ebf\u7684\u6743\u503c\u548c\u6bcf\u4e2a\u795e\u7ecf\u5143\u7684\u504f\u597d\u3002","title":"\u505c\u6b62\u7684\u6761\u4ef6\u6709\u4e0b\u9762\u4e09\u79cd\uff1a"},{"location":"ML/Neural network-Multiple categories/#feed-forward","text":"\u8f93\u5165\u5c42-->\u9690\u85cf\u5c42-->\u8f93\u51fa\u5c42\u9010\u5c42\u7684\u8ba1\u7b97\u6240\u6709\u795e\u7ecf\u5143\u8f93\u51fa\u503c\u7684\u8fc7\u7a0b\u3002","title":"\u524d\u5411\u4f20\u8f93\uff08Feed-Forward\uff09"},{"location":"ML/Neural network-Multiple categories/#error-backpropagation","text":"\u7531\u4e8e\u8f93\u51fa\u5c42\u7684\u503c\u4e0e\u771f\u5b9e\u503c\u4f1a\u5b58\u5728\u8bef\u5dee\uff0c\u7528\u5747\u65b9\u8bef\u5dee\u6765\u8861\u91cf\u9884\u6d4b\u503c\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u7684\u8bef\u5dee \u9006\u5411\u53cd\u9988\u7684\u76ee\u6807\u5c31\u662f\u8ba9E\u51fd\u6570\u7684\u503c\u5c3d\u53ef\u80fd\u7684\u5c0f\uff0c\u800c\u6bcf\u4e2a\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u503c\u662f\u7531\u8be5\u70b9\u7684\u8fde\u63a5\u7ebf\u5bf9\u5e94\u7684\u6743\u91cd\u503c\u548c\u8be5\u5c42\u5bf9\u5e94\u7684\u504f\u597d\u6240\u51b3\u5b9a\u7684\uff0c\u56e0\u6b64\uff0c\u8981\u8ba9\u8bef\u5dee\u51fd\u6570\u8fbe\u5230\u6700\u5c0f\uff0c\u6211\u4eec\u5c31\u8981\u8c03\u6574w\u548cb\u503c\uff0c \u4f7f\u5f97\u8bef\u5dee\u51fd\u6570\u7684\u503c\u6700\u5c0f\u3002 \u5bf9\u76ee\u6807\u51fd\u6570 E \u6c42 w \u548c b \u7684\u504f\u5bfc\u53ef\u4ee5\u5f97\u5230 w \u548c b \u7684\u66f4\u65b0\u91cf\uff0c\u4e0b\u9762\u62ff\u6c42 w \u504f\u5bfc\u6765\u505a\u63a8\u5bfc \u5176\u4e2d \u03b7 \u4e3a\u5b66\u4e60\u7387\uff0c\u53d6\u503c\u901a\u5e38\u4e3a 0.1 ~ 0.3,\u53ef\u4ee5\u7406\u89e3\u4e3a\u6bcf\u6b21\u68af\u5ea6\u6240\u8fc8\u7684\u6b65\u4f10\u3002\u6ce8\u610f\u5230 w_hj \u7684\u503c\u5148\u5f71\u54cd\u5230\u7b2c j \u4e2a\u8f93\u51fa\u5c42\u795e\u7ecf\u5143\u7684\u8f93\u5165\u503ca\uff0c\u518d\u5f71\u54cd\u5230\u8f93\u51fa\u503cy\uff0c\u6839\u636e\u94fe\u5f0f\u6c42\u5bfc\u6cd5\u5219\u6709 \u6839\u636e\u795e\u7ecf\u5143\u8f93\u51fa\u503c a \u7684\u5b9a\u4e49\u6709 Sigmoid \u6c42\u5bfc\u6570\u7684\u5f0f\u5b50\u5982\u4e0b \uff1a \u56e0\u800c\uff1a \u5219\u6743\u91cd w \u7684\u66f4\u65b0\u91cf\u4e3a \uff1a \u540c\u7406\u53ef\u5f97b\u7684\u66f4\u65b0\u91cf\u4e3a\uff1a \u4f46\u8fd9\u4e24\u4e2a\u516c\u5f0f\u53ea\u80fd\u591f\u66f4\u65b0\u8f93\u51fa\u5c42\u4e0e\u524d\u4e00\u5c42\u8fde\u63a5\u7ebf\u7684\u6743\u91cd\u548c\u8f93\u51fa\u5c42\u7684\u504f\u7f6e\uff0c\u539f\u56e0\u662f\u56e0\u4e3a \u03b4 \u503c\u4f9d\u8d56\u4e86\u771f\u5b9e\u503cy\u8fd9\u4e2a\u53d8\u91cf\uff0c\u4f46\u662f\u6211\u4eec\u53ea\u77e5\u9053\u8f93\u51fa\u5c42\u7684\u771f\u5b9e\u503c\u800c\u4e0d\u77e5\u9053\u6bcf\u5c42\u9690\u85cf\u5c42\u7684\u771f\u5b9e\u503c\uff0c\u5bfc\u81f4\u65e0\u6cd5\u8ba1\u7b97\u6bcf\u5c42\u9690\u85cf\u5c42\u7684 \u03b4 \u503c\uff0c\u6240\u4ee5\u6211\u4eec\u5e0c\u671b\u80fd\u591f\u5229\u7528 i+1 \u5c42\u7684 \u03b4 \u503c\u6765\u8ba1\u7b97 i \u5c42\u7684 \u03b4 \u503c\uff0c\u800c\u6070\u6070\u901a\u8fc7\u4e00\u4e9b\u5217\u6570\u5b66\u8f6c\u6362\u540e\u53ef\u4ee5\u505a\u5230\uff0c\u8fd9\u4e5f\u5c31\u662f\u9006\u5411\u53cd\u9988\u540d\u5b57\u7684\u7531\u6765\uff0c\u516c\u5f0f\u5982\u4e0b: \u4ece\u4e0a\u9762\u7684\u5f0f\u5b50\uff0c\u53ea\u9700\u8981\u77e5\u9053\u4e0b\u4e00\u5c42\u7684\u6743\u91cd\u7684\u795e\u7ecf\u5143\u8f93\u51fa\u5c42\u7684\u503c\u5c31\u53ef\u4ee5\u8ba1\u7b97\u51fa\u4e0a\u4e00\u5c42\u7684 \u03b4 \u503c \uff0c\u53ea\u8981\u901a\u8fc7\u4e0d\u65ad\u5730\u5229\u7528\u4e0a\u9762\u7684\u5f0f\u5b50\u5c31\u53ef\u4ee5\u5c31\u53ef\u4ee5\u66f4\u65b0\u9690\u85cf\u5c42\u7684\u5168\u90e8\u6743\u91cd\u548c\u504f\u7f6e\u3002","title":"\u8bef\u5dee\u9006\u4f20\u8f93\uff08error BackPropagation\uff09"},{"location":"ML/Neural network-Multiple categories/#_3","text":"","title":"\u4e0b\u9762\u7ed9\u51fa\u6b64\u6b21\u5b9e\u9a8c\u7684\u6e90\u7801\uff1a"},{"location":"ML/Neural network-Multiple categories/#bpnetworkpy","text":"import numpy as np def tanh ( x ): return np . tanh ( x ) def tan_deriv ( x ): return 1.0 - np . tanh ( x ) * np . tan ( x ) # sigmoid def logistic ( x ): return 1 / ( 1 + np . exp ( - x )) def logistic_deriv ( x ): return logistic ( x ) * ( 1 - logistic ( x )) class NeuralNetwork : def __init__ ( self , layers , activation = 'tanh' ): if activation == 'logistic' : self . activation = logistic self . activation_deriv == logistic_deriv elif activation == 'tanh' : self . activation = tanh self . activation_deriv = tan_deriv self . weights = [] for i in range ( 1 , len ( layers ) - 1 ): self . weights . append (( 2 * np . random . random (( layers [ i - 1 ] + 1 , layers [ i ] + 1 )) - 1 ) * 0.25 ) self . weights . append (( 2 * np . random . random (( layers [ i ] + 1 , layers [ i + 1 ])) - 1 ) * 0.25 ) def fit ( self , X , y , learning_rate = 0.2 , epochs = 10000 ): X = np . atleast_2d ( X ) temp = np . ones ([ X . shape [ 0 ], X . shape [ 1 ] + 1 ]) temp [:, 0 : - 1 ] = X X = temp y = np . array ( y ) for k in range ( epochs ): i = np . random . randint ( X . shape [ 0 ]) a = [ X [ i ]] for l in range ( len ( self . weights )): a . append ( self . activation ( np . dot ( a [ l ], self . weights [ l ]))) error = y [ i ] - a [ - 1 ] deltas = [ error * self . activation_deriv ( a [ - 1 ])] for l in range ( len ( a ) - 2 , 0 , - 1 ): deltas . append ( deltas [ - 1 ] . dot ( self . weights [ l ] . T ) * self . activation_deriv ( a [ l ])) deltas . reverse () for i in range ( len ( self . weights )): layer = np . atleast_2d ( a [ i ]) delta = np . atleast_2d ( deltas [ i ]) self . weights [ i ] += learning_rate * layer . T . dot ( delta ) def predict ( self , x ): x = np . array ( x ) temp = np . ones ( x . shape [ 0 ] + 1 ) temp [ 0 : - 1 ] = x a = temp for l in range ( 0 , len ( self . weights )): a = self . activation ( np . dot ( a , self . weights [ l ])) return a","title":"BPNetwork.py"},{"location":"ML/Neural network-Multiple categories/#runpy","text":"from BPNetwork import NeuralNetwork import numpy as np train = [ 0 , 0 , 0 , 0 , 0 ] test = [ 0 , 0 , 0 , 0 , 0 ] train [ 0 ] = [[ 0 , 1 , 1 , 0 , 0 ], [ 0 , 0 , 1 , 0 , 0 ], [ 0 , 0 , 1 , 0 , 0 ], [ 0 , 0 , 1 , 0 , 0 ], [ 0 , 1 , 1 , 1 , 0 ]] train [ 1 ] = [[ 1 , 1 , 1 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 1 ], [ 0 , 1 , 1 , 1 , 0 ], [ 1 , 0 , 0 , 0 , 0 ], [ 1 , 1 , 1 , 1 , 1 ]] train [ 2 ] = [[ 1 , 1 , 1 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 1 ], [ 0 , 1 , 1 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 1 ], [ 1 , 1 , 1 , 1 , 0 ]] train [ 3 ] = [[ 0 , 0 , 0 , 1 , 0 ], [ 0 , 0 , 1 , 1 , 0 ], [ 0 , 1 , 0 , 1 , 0 ], [ 1 , 1 , 1 , 1 , 1 ], [ 0 , 0 , 0 , 1 , 0 ]] train [ 4 ] = [[ 1 , 1 , 1 , 1 , 1 ], [ 1 , 0 , 0 , 0 , 0 ], [ 1 , 1 , 1 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 1 ], [ 1 , 1 , 1 , 1 , 0 ]] test [ 0 ] = [[ 0 , 0 , 1 , 1 , 0 ], [ 0 , 0 , 1 , 1 , 0 ], [ 0 , 1 , 0 , 1 , 0 ], [ 0 , 0 , 0 , 1 , 0 ], [ 0 , 1 , 1 , 1 , 0 ]] test [ 1 ] = [[ 1 , 1 , 1 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 1 ], [ 0 , 1 , 1 , 1 , 0 ], [ 1 , 0 , 0 , 0 , 1 ], [ 1 , 1 , 1 , 1 , 1 ]] test [ 2 ] = [[ 1 , 1 , 1 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 1 ], [ 0 , 1 , 1 , 1 , 0 ], [ 1 , 0 , 0 , 0 , 1 ], [ 1 , 1 , 1 , 1 , 0 ]] test [ 3 ] = [[ 0 , 1 , 1 , 1 , 0 ], [ 0 , 1 , 0 , 0 , 0 ], [ 0 , 1 , 1 , 1 , 0 ], [ 0 , 0 , 0 , 1 , 0 ], [ 0 , 1 , 1 , 1 , 0 ]] test [ 4 ] = [[ 0 , 1 , 1 , 1 , 1 ], [ 0 , 1 , 0 , 0 , 0 ], [ 0 , 1 , 1 , 1 , 0 ], [ 0 , 0 , 0 , 1 , 0 ], [ 1 , 1 , 1 , 1 , 0 ]] nn = NeuralNetwork ([ 25 , 50 , 5 ], 'tanh' ) # temp = init[0] for i in range ( 5 ): X = np . array ( train [ i ]) y = np . array ( test [ i ]) nn . fit ( X , y ) for j in train [ i ]: print ( nn . predict ( j ))","title":"Run.py"},{"location":"ML/Neural network-Multiple categories/#_4","text":"","title":"\u5b9e\u9a8c\u9884\u6d4b\u6d4b\u8bd5\u96c6\u7ed3\u679c\uff1a"}]}